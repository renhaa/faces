\section{Introduction}


A distinction between machine learning models are that between \emph{disciminative} and \emph{generative} models. In discriminative models we assign a label to a datapoint. For example given an image, which category does it belong to - is it a cat or a horse? Generative models however tries to approximate samples from a data distribution from a learned distribution.

In this research project we will explore different generative models on the domain of face synthesis. We can distinguish two main types of generative models: likelihood based models, which include Variational Autoencoders (VAEs) and implicit models such as Generative Adversarial Networks (GANs)\cite{vqvae2}.

In this project we will implement Principal Component Analysis(PCA) a VAE and a GAN and compare the results of generating faces with these three methods.

We will start in the next
exploring different architectural implementation along the way.

The expected outcome of theis project is theree folde

1) gaining an overview of modern generative models trhough a literature survery. Here we will review recent litterature and explore there different recent  architectural implementation of VAEs and GANS. We will provide the nessecary theory along the way. Wwith we will do in the next section

2) gain practical understanding by implementing versions of the different models and training them two different datasets.

3) Finally we will Furthermore we will explore the latent space of pre trained models and show that we can use these to do state-of-the-art face synthesis and semantic face editing.
