\section{Introduction}

A distinction between machine learning models are that between \emph{disciminative} and \emph{generative} models. In discriminative models we assign a label to a datapoint. For example given an image, which category does it belong to - is it a cat or a horse? Generative models however tries to approximate samples from a data distribution from a learned distribution.

In this research project we will explore different generative models on the domain of face synthesis. We can distinguish two main types of generative models: likelihood based models, which include Variational Autoencoders (VAEs) and implicit models such as Generative Adversarial Networks (GANs)\cite{vqvae2}.

In this project we will implement Principal Component Analysis(PCA) a VAE and a GAN and compare the results of generating faces with these three methods. We will start in section \ref{theory} with outlining the theory behind each model and  then survey recent literature for different architectural implementations.

The expected outcome of this project is three-fold:

1) Gaining an overview of modern generative models through a literature survey. Here we will review recent literature and explore there different recent architectural implementation of VAEs and GANS.

2) Gain practical understanding by implementing versions of the different models and training them two different datasets.

3) Explore very recent work using  a pretrained model and show that we can use this model to do state-of-the-art face synthesis and semantic face editing by manipulating the latent space of model.
