\chapter{Theory}

%
% \section{Inception Score}
% \url{https://machinelearningmastery.com/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images/}
%

% \section{Principal Component Analasyis. }

\section{Probabilistic models}
We assume that the observed variable $\mathbf{x}$ is a sample from the true distribution $p^*(\mathbf{x})$.\cite{vaeintro} Out goal is to approximate the true distribution with a model such that

\begin{align}
  p_\theta(\mathbf{x})\approx p^*(\mathbf{x})
\end{align}

Now, how do we ego about actually modeling this distribution $p_\theta(\mathbf{x})$?. We can use Neural networks to parametrize the distribution.

The log-probability of the data is
\begin{align}
  \log p_\theta(\mathcal{X}) = \sum_{\mathbf{x}\in\mathcal{X}} p_\theta(\mathbf{x})
\end{align}

Maximization of the log-likelihood is equivalent to minimizing the KullBack-Leibler divergence.

The KullBack-Leibler divergence is given by

\begin{align}
D_{\text{KL}}(p_\theta,q_\phi) = -\sum_{\mathbf{x}\in\mathcal{X}}p_\theta(\mathbf{x})\log \frac{q_\phi(\mathbf{x})}{p_\theta(\mathbf{x})}
\end{align}

% \section{Survey}

\section{Variational Autoencoders.}
The encoder network models$p_\theta(\mathbf{z}|\mathbf{x})$ while the encoder network models $p_\theta(\mathbf{x}|\mathbf{z})$


\section{GANs}



% \paragraph{Face Aging}
% \textit{Face Aging With Conditional Generative Adversarial Networks} (2017) \cite{faceaging}

% \section{3D Reconstruction}
%
% \textit{Projective Structure from Facial Motion}(2017)\cite{ProjectiveStructure}
%
% \textit{Apathy is the Root of all Expressions}(2017)\cite{apathy}
%
% In the paper \textit{"Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression"}(2017)\cite{largepose}
% the authors used a Convolutional Neural Network to reconstruct the 3D facial geometry from just a single image. The model work under arbitrary poses
% and expressions and without the need of a 3D Morphable Model.
